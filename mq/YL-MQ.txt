消息中间件整理
	一、为什么用mq(使用场景)
		1、降低系统之间的耦合性，解耦
			订单系统订单完成一系列操作，赛事报名、减库存、消费数据类型统计，活动发券等等，订单发送消息给MQ，当活动有变化时，订单系统不需要做修改
		2、异步（快速响应用户）
			例如：用户注册-送积分-发短信等等操作，注册服务只需发送消息给MQ，积分系统和短信系统去MQ消费消息，减少响应时间，提高用户体验				
		3、削峰
			弹幕发送，或者抢购活动，坐公交刷二维码，某个高峰期请求量非常大，并发量很大，导致服务器宕机或数据库宕机，用MQ削峰，
			假如服务器一秒最多只能处理1000请求，请求先发送至MQ，服务器每秒消费不超过1000请求就可以了，等不是高峰期是慢慢处理
	
	二、用MQ有什么坏处
		1、系统间的复杂程度变高，需要考虑
			MQ宕机了怎么办。消息没消费到？消息重复消费？消息的消费顺序如何保证？
		2、数据一致性问题
			用户注册成功发送消息到MQ，用户接收到的是成功。假如在积分系统加积分没有成功，实际上是不成功的，导致数据不一致。
		3、系统可能行降低
			解耦场景，本来系统间调用直接API调用，现在中间加上MQ，如果MQ挂了就崩了。
	
	三、你们用的是什么MQ，rabbitMQ、activityMQ，rocketMQ，kafka，它们有什么异同、优缺点。
		1、activityMQ 
			吞吐量：万级吞吐量
			数据丢失：小概率消息丢失
			社区活跃度：不是很活跃，版本更新相对慢。bug修复慢。目前不推荐使用
			国内公司前两年用的多
			不是分布式，可集群实现高可用
			
		2、rabbitMQ
			吞吐量：数万级吞吐量
			数据丢失：不会
			社区活跃度：很活跃，版本更新相对高。bug修复快。推荐使用
			不是分布式。可部署镜像集群实现高可用。镜像集群存在所有queue在每台服务上都有镜像（副本），假如把磁盘都写满了？性能开销过高，消息需要同步所有机器，会导致网络带宽压力和消耗很重。没有做到分布式存储
			源码为elang，阅读困难，有可视化管理系统，可以很明确的看到MQ的各种监控数据
			响应为微秒级，响应最快
			
		3、rocketMQ
			十万级吞吐量
			通过配置实现数据0丢失
			分布式系统
			源码为Java。阿里开发品牌
			
		4、kafka
			十万级吞吐量
			通过配置实现数据0丢失
			分布式系统 数据分布式存储
			功能相对简单，适合做大数据日志及数据采集场景
	
	四、如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？
		kafka假如消费者系统kill进程重启，而消费者最后消费的数据的offset还没有提交至ZK，就会存在重复消费的问题。
		1、假如消费信息是插入数据库，先判断下是否库里之前有，没有就插入，有就update
		2、假如是存入redis，redis的set方法本身是具有幂等性的
		3、不是上面两种场景，在生产者生成消息时加一个唯一ID，消费者把这个ID存redis，判断是否已有消费
		4、根据具体业务来设计
		
	五、如何保证消息不丢失？
		上面情况消息会丢失？
			1、rabbitMQ
				1、生产者发送消息到MQservice，网络延迟。以为发送成功，其实并没有。
					解决方案：
						1、rabbitMQ的事务机制，channel.tx开启事务，当发送失败时进行重试。
							缺点：事务是同步阻塞的，会影响MQ的吞吐量
						2、confirm异步机制。MQ会给生产者回调ack(写入成功)，nack(失败);
				2、MQservice消息还没被消费时挂了，导致消息丢失
					rabbit设置queen类型为持久化，生产者发送消息时deliveryMode设置为2，将消息设置成持久化，rabbit就会把消息持久化到磁盘。重启是从磁盘读取消费。假如还有少量消息在内存中没被持久化，会丢失。
				3、消费者开启aotuack，消费者拿到消息还没处理就告诉MQ已消费。而实际上并没有消费成功
					手动ack，当消费处理成功才ack到MQ。
					
			2、kafka
				集群部署，leader数据还没同步到follower，leader宕机，导致数据丢失。
					解决方案：配置参数使MQleader数据同步到所有follower才算加入MQ成功，否则不算，需要重试
					给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
					在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
					在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
					在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。
	
	六、消息的顺序行
		rabbitMQ 
			rabbitMQ本身是有顺序的，但是由于一个queen可以被多个消费者同时消费，就存在消息的消费顺序问题。
				保证一个queen只有一个消费者消费。可以多个queen多个消费者。或者一个queen一个消费者，但是在消费者那边使用内存队列把消息分发给不同的worker去处理消息
		
		kafka
			kafka一个topic对应对多个partition，一个partition对应一个consumer，多个consumer
			
	七、消息堆积、消息延迟、消息过期
		消息堆积
			假设kafka堆积几百万条数据，新写一个topic，partition数量为原先的10倍，consumer也是10倍，原先的consumer重新写入新的topic，已十倍的速度来消费
		消息延时过期
			凌晨批量补偿
		MQ快写满了
			快速消费在，消费直接丢掉，后面在补偿
		
			
			
		
	
